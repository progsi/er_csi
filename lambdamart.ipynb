{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LambdaMART\n",
    "This notebook shows examples of how we optimize [LambdaMART](https://www.microsoft.com/en-us/research/uploads/prod/2016/02/MSR-TR-2010-82.pdf) for online video cover song identification. \n",
    "\n",
    "## Requirements\n",
    "- set the variables `DATASET_PATH` and `METADATA_PARQUET_PATH` at the beginning of the first cell\n",
    "- prepare data as described in `README`\n",
    "- the pairwise predictions per model `MODEL` and dataset `DATASET` under `preds/MODEL/DATASET/preds.pt\"`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import scipy\n",
    "from torchmetrics.retrieval import RetrievalNormalizedDCG, RetrievalMAP\n",
    "from src.dataset import TestDataset, OnlineCoverSongDataset\n",
    "from src.evaluation import RetrievalEvaluation\n",
    "from src.baselines.blocking import Blocker\n",
    "from rapidfuzz import fuzz\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "\n",
    "DATASET_PATH = \"/data/csi_datasets/\"\n",
    "METADATA_PARQUET_PATH = \"/data/yt_metadata.parquet\"\n",
    "\n",
    "mean_average_precision = RetrievalMAP(empty_target_action=\"skip\")\n",
    "\n",
    "def mean_rank_1(preds, target):\n",
    "        \"\"\"\n",
    "        Compute the mean rank for relevant items in the predictions.\n",
    "        Args:\n",
    "            preds (torch.Tensor): A tensor of predicted scores (higher scores indicate more relevant items).\n",
    "            target (torch.Tensor): A tensor of true relationships (0 for irrelevant, 1 for relevant).\n",
    "        Returns:\n",
    "            float: The mean rank of relevant items for each query.\n",
    "        \"\"\"\n",
    "        has_positives = torch.sum(target, 1) > 0\n",
    "        \n",
    "        _, spred = torch.topk(preds, preds.size(1), dim=1)\n",
    "        found = torch.gather(target, 1, spred)\n",
    "        temp = torch.arange(preds.size(1)).cpu().float() * 1e-6\n",
    "        _, sel = torch.topk(found - temp, 1, dim=1)\n",
    "        \n",
    "        sel = sel.float()\n",
    "        sel[~has_positives] = torch.nan\n",
    "        \n",
    "        mr1 = torch.nanmean((sel+1).float())\n",
    "\n",
    "        del sel, found, temp, spred, has_positives\n",
    "        torch.cuda.empty_cache()\n",
    "        return mr1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_preds(model, dataset):\n",
    "\n",
    "    # get audio preds\n",
    "    data = get_dataset(model, dataset)\n",
    "    preds = data.get_csi_pred_matrix(model).cpu()\n",
    "    preds = torch.where(preds == float('-inf'), 0, preds)\n",
    "    return preds\n",
    "\n",
    "def get_fuzzy_preds(dataset):\n",
    "\n",
    "    # get text preds\n",
    "    blocker = Blocker(blocking_func=fuzz.token_ratio, threshold=0.5)\n",
    "    left_df, right_df = dataset.get_dfs_by_task(\"svShort\")\n",
    "    preds = blocker.predict(left_df, right_df).cpu()\n",
    "    preds = preds.fill_diagonal_(-float('inf')) / 100\n",
    "    preds = torch.where(preds == float('-inf'), 0, preds)\n",
    "    return preds\n",
    "\n",
    "\n",
    "def get_text_preds(model, dataset):\n",
    "    if model == \"fuzzy\":\n",
    "        return get_fuzzy_preds(get_dataset(model, dataset))\n",
    "    else:\n",
    "        return torch.load(f\"preds/{model}/{dataset}/preds.pt\")\n",
    "\n",
    "\n",
    "def get_model_mode(model):\n",
    "    if model == \"fuzzy\" or model == \"sentence-transformers\":\n",
    "        return \"tvShort\"\n",
    "    elif model == \"ditto\" or model == \"rsupcon\":\n",
    "        return \"rLong\"\n",
    "    elif model == \"hiergat_split\":\n",
    "        return \"rShort\"\n",
    "\n",
    "\n",
    "def get_dataset(model, dataset):\n",
    "    csi_path = DATASET_PATH\n",
    "    metadata_path = METADATA_PARQUET_PATH\n",
    "    if model == \"sentence-transformers\":\n",
    "        return OnlineCoverSongDataset(\n",
    "                dataset,\n",
    "                csi_path,\n",
    "                metadata_path,\n",
    "                get_model_mode(model)\n",
    "        )  \n",
    "    else:\n",
    "        return TestDataset(\n",
    "        dataset,\n",
    "        csi_path,\n",
    "        metadata_path,\n",
    "        tokenizer=\"roberta-base\"\n",
    "        )\n",
    "\n",
    "\n",
    "def get_ensemble_data(text_model, audio_model, dataset):\n",
    "    \n",
    "    data = get_dataset(text_model, dataset)\n",
    "    \n",
    "    # get preds\n",
    "    text_preds = get_text_preds(text_model, dataset).cpu().numpy()\n",
    "    audio_preds = get_audio_preds(audio_model, dataset).cpu().numpy()\n",
    "\n",
    "    # get ground truth\n",
    "    Y = data.get_target_matrix().to(float).cpu()\n",
    "    \n",
    "    # get indexes\n",
    "    m, n = Y.shape\n",
    "    indexes = torch.arange(m).view(-1, 1).expand(-1, n).cpu()\n",
    "\n",
    "    # last transform\n",
    "    y_train = Y.cpu().numpy().flatten()\n",
    "    X_train = np.concatenate([text_preds.reshape(-1, 1), audio_preds.reshape(-1, 1)], axis=1)\n",
    "\n",
    "    # get query info array\n",
    "    qids = indexes.cpu().numpy().flatten()\n",
    "    return X_train, y_train, qids\n",
    "\n",
    "def compute_metrics(X_test, y_test, qids, ltr_model, out_path):\n",
    "\n",
    "    preds = ltr_model.predict(X_test)\n",
    "    # unflatten\n",
    "    def unflatten(t):\n",
    "        return torch.tensor(t.reshape((int(np.sqrt(len(t))), int(np.sqrt(len(t))))))\n",
    "    \n",
    "    preds = unflatten(preds)\n",
    "    # normalize\n",
    "    preds = (preds - torch.min(preds)) / (torch.max(preds) - torch.min(preds))\n",
    "    \n",
    "    target = unflatten(y_test)\n",
    "    indexes = unflatten(qids)\n",
    "\n",
    "    torch.save(preds, os.path.join(out_path, \"ypreds.pt\"))\n",
    "    torch.save(target, os.path.join(out_path, \"ytrue.pt\"))\n",
    "\n",
    "    map_result = mean_average_precision(preds.cpu(), target.cpu(), indexes.cpu())\n",
    "    mr1_result = mean_rank_1(preds, target)\n",
    "    return map_result, mr1_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"objective\": \"rank:map\", \n",
    "    \"lambdarank_pair_method\": \"topk\", \n",
    "    \"lambdarank_num_pair_per_sample\": 50\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuzzy Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRanker(base_score=None, booster=None, callbacks=None, colsample_bylevel=None,\n",
       "          colsample_bynode=None, colsample_bytree=None, device=None,\n",
       "          early_stopping_rounds=None, enable_categorical=False,\n",
       "          eval_metric=None, feature_types=None, gamma=None, grow_policy=None,\n",
       "          importance_type=None, interaction_constraints=None,\n",
       "          lambdarank_num_pair_per_sample=50, lambdarank_pair_method=&#x27;topk&#x27;,\n",
       "          learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "          max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "          max_leaves=None, min_child_weight=None, missing=nan,\n",
       "          monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "          n_jobs=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRanker</label><div class=\"sk-toggleable__content\"><pre>XGBRanker(base_score=None, booster=None, callbacks=None, colsample_bylevel=None,\n",
       "          colsample_bynode=None, colsample_bytree=None, device=None,\n",
       "          early_stopping_rounds=None, enable_categorical=False,\n",
       "          eval_metric=None, feature_types=None, gamma=None, grow_policy=None,\n",
       "          importance_type=None, interaction_constraints=None,\n",
       "          lambdarank_num_pair_per_sample=50, lambdarank_pair_method=&#x27;topk&#x27;,\n",
       "          learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "          max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "          max_leaves=None, min_child_weight=None, missing=nan,\n",
       "          monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "          n_jobs=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRanker(base_score=None, booster=None, callbacks=None, colsample_bylevel=None,\n",
       "          colsample_bynode=None, colsample_bytree=None, device=None,\n",
       "          early_stopping_rounds=None, enable_categorical=False,\n",
       "          eval_metric=None, feature_types=None, gamma=None, grow_policy=None,\n",
       "          importance_type=None, interaction_constraints=None,\n",
       "          lambdarank_num_pair_per_sample=50, lambdarank_pair_method='topk',\n",
       "          learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "          max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "          max_leaves=None, min_child_weight=None, missing=nan,\n",
       "          monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "          n_jobs=None, ...)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_train, y_train, qids_train = get_ensemble_data(\"fuzzy\", \"coverhunter\", \"shs100k_1000\")\n",
    "X_val, y_val, qids_val = get_ensemble_data(\"fuzzy\", \"coverhunter\", \"shs100k2_val\")\n",
    "\n",
    "model_fuzzy_ch = xgb.XGBRanker(**params)\n",
    "model_fuzzy_ch.fit(X_train, y_train, qid=qids_train, eval_set=[(X_val, y_val)], eval_qid=[qids_val])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.8973), tensor(4.3458))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_model = \"fuzzy\"\n",
    "audio_model = \"coverhunter\"\n",
    "dataset = \"shs100k2_test\"\n",
    "out_path = os.path.join(\"preds\", f\"{text_model}_{audio_model}\", dataset)\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "X_test, y_test, qids_test = get_ensemble_data(text_model, audio_model , dataset)\n",
    "mapr, mr1r = compute_metrics(X_test, y_test, qids_test, model_fuzzy_ch, out_path)\n",
    "mapr, mr1r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S-BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRanker(base_score=None, booster=None, callbacks=None, colsample_bylevel=None,\n",
       "          colsample_bynode=None, colsample_bytree=None, device=None,\n",
       "          early_stopping_rounds=None, enable_categorical=False,\n",
       "          eval_metric=None, feature_types=None, gamma=None, grow_policy=None,\n",
       "          importance_type=None, interaction_constraints=None,\n",
       "          lambdarank_num_pair_per_sample=50, lambdarank_pair_method=&#x27;topk&#x27;,\n",
       "          learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "          max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "          max_leaves=None, min_child_weight=None, missing=nan,\n",
       "          monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "          n_jobs=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRanker</label><div class=\"sk-toggleable__content\"><pre>XGBRanker(base_score=None, booster=None, callbacks=None, colsample_bylevel=None,\n",
       "          colsample_bynode=None, colsample_bytree=None, device=None,\n",
       "          early_stopping_rounds=None, enable_categorical=False,\n",
       "          eval_metric=None, feature_types=None, gamma=None, grow_policy=None,\n",
       "          importance_type=None, interaction_constraints=None,\n",
       "          lambdarank_num_pair_per_sample=50, lambdarank_pair_method=&#x27;topk&#x27;,\n",
       "          learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "          max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "          max_leaves=None, min_child_weight=None, missing=nan,\n",
       "          monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "          n_jobs=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRanker(base_score=None, booster=None, callbacks=None, colsample_bylevel=None,\n",
       "          colsample_bynode=None, colsample_bytree=None, device=None,\n",
       "          early_stopping_rounds=None, enable_categorical=False,\n",
       "          eval_metric=None, feature_types=None, gamma=None, grow_policy=None,\n",
       "          importance_type=None, interaction_constraints=None,\n",
       "          lambdarank_num_pair_per_sample=50, lambdarank_pair_method='topk',\n",
       "          learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "          max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "          max_leaves=None, min_child_weight=None, missing=nan,\n",
       "          monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "          n_jobs=None, ...)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, qids_train = get_ensemble_data(\"sentence-transformers\", \"coverhunter\", \"shs100k_1000\")\n",
    "X_val, y_val, qids_val = get_ensemble_data(\"sentence-transformers\", \"coverhunter\", \"shs100k2_val\")\n",
    "\n",
    "model_sbert_ch = xgb.XGBRanker(**params)\n",
    "model_sbert_ch.fit(X_train, y_train, qid=qids_train, eval_set=[(X_val, y_val)], eval_qid=[qids_val])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.9303), tensor(3.8029))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_model = \"sentence-transformers\"\n",
    "audio_model = \"coverhunter\"\n",
    "dataset = \"shs100k2_test\"\n",
    "out_path = os.path.join(\"preds\", f\"{text_model}_{audio_model}\", dataset)\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "X_test, y_test, qids_test = get_ensemble_data(text_model, audio_model , dataset)\n",
    "mapr, mr1r = compute_metrics(X_test, y_test, qids_test, model_sbert_ch, out_path)\n",
    "mapr, mr1r\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
