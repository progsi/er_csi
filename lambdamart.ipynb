{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/miniconda3/envs/torch21/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import scipy\n",
    "from torchmetrics.retrieval import RetrievalNormalizedDCG, RetrievalMAP\n",
    "from src.dataset import TestDataset, OnlineCoverSongDataset\n",
    "from src.evaluation import RetrievalEvaluation\n",
    "from src.baselines.blocking import Blocker\n",
    "from rapidfuzz import fuzz\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "mean_average_precision = RetrievalMAP(empty_target_action=\"skip\")\n",
    "\n",
    "def mean_rank_1(preds, target):\n",
    "        \"\"\"\n",
    "        Compute the mean rank for relevant items in the predictions.\n",
    "        Args:\n",
    "            preds (torch.Tensor): A tensor of predicted scores (higher scores indicate more relevant items).\n",
    "            target (torch.Tensor): A tensor of true relationships (0 for irrelevant, 1 for relevant).\n",
    "        Returns:\n",
    "            float: The mean rank of relevant items for each query.\n",
    "        \"\"\"\n",
    "        has_positives = torch.sum(target, 1) > 0\n",
    "        \n",
    "        _, spred = torch.topk(preds, preds.size(1), dim=1)\n",
    "        found = torch.gather(target, 1, spred)\n",
    "        temp = torch.arange(preds.size(1)).cpu().float() * 1e-6\n",
    "        _, sel = torch.topk(found - temp, 1, dim=1)\n",
    "        \n",
    "        sel = sel.float()\n",
    "        sel[~has_positives] = torch.nan\n",
    "        \n",
    "        mr1 = torch.nanmean((sel+1).float())\n",
    "\n",
    "        del sel, found, temp, spred, has_positives\n",
    "        torch.cuda.empty_cache()\n",
    "        return mr1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_preds(model, dataset):\n",
    "\n",
    "    # get audio preds\n",
    "    data = get_dataset(model, dataset)\n",
    "    preds = data.get_csi_pred_matrix(model).cpu()\n",
    "    preds = torch.where(preds == float('-inf'), 0, preds)\n",
    "    return preds\n",
    "\n",
    "def get_fuzzy_preds(dataset):\n",
    "\n",
    "    # get text preds\n",
    "    blocker = Blocker(blocking_func=fuzz.token_ratio, threshold=0.5)\n",
    "    left_df, right_df = dataset.get_dfs_by_task(\"svShort\")\n",
    "    preds = blocker.predict(left_df, right_df).cpu()\n",
    "    preds = preds.fill_diagonal_(-float('inf')) / 100\n",
    "    preds = torch.where(preds == float('-inf'), 0, preds)\n",
    "    return preds\n",
    "\n",
    "\n",
    "def get_text_preds(model, dataset):\n",
    "    if model == \"fuzzy\":\n",
    "        return get_fuzzy_preds(get_dataset(model, dataset))\n",
    "    else:\n",
    "        return torch.load(f\"preds/{model}/{dataset}/preds.pt\")\n",
    "\n",
    "\n",
    "def get_model_mode(model):\n",
    "    if model == \"fuzzy\" or model == \"sentence-transformers\":\n",
    "        return \"tvShort\"\n",
    "    elif model == \"ditto\" or model == \"rsupcon\":\n",
    "        return \"rLong\"\n",
    "    elif model == \"hiergat_split\":\n",
    "        return \"rShort\"\n",
    "\n",
    "\n",
    "def get_dataset(model, dataset):\n",
    "    csi_path = \"/data/csi_datasets/\"\n",
    "    metadata_path = \"/data/yt_metadata.parquet\"\n",
    "    if model == \"sentence-transformers\":\n",
    "        return OnlineCoverSongDataset(\n",
    "                dataset,\n",
    "                csi_path,\n",
    "                metadata_path,\n",
    "                get_model_mode(model)\n",
    "        )  \n",
    "    else:\n",
    "        return TestDataset(\n",
    "        dataset,\n",
    "        csi_path,\n",
    "        metadata_path,\n",
    "        tokenizer=\"roberta-base\"\n",
    "        )\n",
    "\n",
    "\n",
    "def get_ensemble_data(text_model, audio_model, dataset):\n",
    "    \n",
    "    data = get_dataset(text_model, dataset)\n",
    "    \n",
    "    # get preds\n",
    "    text_preds = get_text_preds(text_model, dataset).cpu().numpy()\n",
    "    audio_preds = get_audio_preds(audio_model, dataset).cpu().numpy()\n",
    "\n",
    "    # get ground truth\n",
    "    Y = data.get_target_matrix().to(float).cpu()\n",
    "    \n",
    "    # get indexes\n",
    "    m, n = Y.shape\n",
    "    indexes = torch.arange(m).view(-1, 1).expand(-1, n).cpu()\n",
    "\n",
    "    # last transform\n",
    "    y_train = Y.cpu().numpy().flatten()\n",
    "    X_train = np.concatenate([text_preds.reshape(-1, 1), audio_preds.reshape(-1, 1)], axis=1)\n",
    "\n",
    "    # get query info array\n",
    "    qids = indexes.cpu().numpy().flatten()\n",
    "    return X_train, y_train, qids\n",
    "\n",
    "def compute_metrics(X_test, y_test, qids, ltr_model, out_path):\n",
    "\n",
    "    preds = ltr_model.predict(X_test)\n",
    "    # unflatten\n",
    "    def unflatten(t):\n",
    "        return torch.tensor(t.reshape((int(np.sqrt(len(t))), int(np.sqrt(len(t))))))\n",
    "    \n",
    "    preds = unflatten(preds)\n",
    "    # normalize\n",
    "    preds = (preds - torch.min(preds)) / (torch.max(preds) - torch.min(preds))\n",
    "    \n",
    "    target = unflatten(y_test)\n",
    "    indexes = unflatten(qids)\n",
    "\n",
    "    torch.save(preds, os.path.join(out_path, \"ypreds.pt\"))\n",
    "    torch.save(target, os.path.join(out_path, \"ytrue.pt\"))\n",
    "\n",
    "    map_result = mean_average_precision(preds.cpu(), target.cpu(), indexes.cpu())\n",
    "    mr1_result = mean_rank_1(preds, target)\n",
    "    return map_result, mr1_result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fuzzy Matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRanker(base_score=None, booster=None, callbacks=None, colsample_bylevel=None,\n",
       "          colsample_bynode=None, colsample_bytree=None, device=None,\n",
       "          early_stopping_rounds=None, enable_categorical=False,\n",
       "          eval_metric=None, feature_types=None, gamma=None, grow_policy=None,\n",
       "          importance_type=None, interaction_constraints=None,\n",
       "          lambdarank_num_pair_per_sample=6, lambdarank_pair_method=&#x27;topk&#x27;,\n",
       "          learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "          max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "          max_leaves=None, min_child_weight=None, missing=nan,\n",
       "          monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "          n_jobs=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRanker</label><div class=\"sk-toggleable__content\"><pre>XGBRanker(base_score=None, booster=None, callbacks=None, colsample_bylevel=None,\n",
       "          colsample_bynode=None, colsample_bytree=None, device=None,\n",
       "          early_stopping_rounds=None, enable_categorical=False,\n",
       "          eval_metric=None, feature_types=None, gamma=None, grow_policy=None,\n",
       "          importance_type=None, interaction_constraints=None,\n",
       "          lambdarank_num_pair_per_sample=6, lambdarank_pair_method=&#x27;topk&#x27;,\n",
       "          learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "          max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "          max_leaves=None, min_child_weight=None, missing=nan,\n",
       "          monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "          n_jobs=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRanker(base_score=None, booster=None, callbacks=None, colsample_bylevel=None,\n",
       "          colsample_bynode=None, colsample_bytree=None, device=None,\n",
       "          early_stopping_rounds=None, enable_categorical=False,\n",
       "          eval_metric=None, feature_types=None, gamma=None, grow_policy=None,\n",
       "          importance_type=None, interaction_constraints=None,\n",
       "          lambdarank_num_pair_per_sample=6, lambdarank_pair_method='topk',\n",
       "          learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "          max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "          max_leaves=None, min_child_weight=None, missing=nan,\n",
       "          monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "          n_jobs=None, ...)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    \"objective\": \"rank:map\", \n",
    "    \"lambdarank_pair_method\": \"topk\", \n",
    "    \"lambdarank_num_pair_per_sample\": 6\n",
    "    }\n",
    "\n",
    "X_train, y_train, qids_train = get_ensemble_data(\"fuzzy\", \"coverhunter\", \"shs100k_1000\")\n",
    "X_val, y_val, qids_val = get_ensemble_data(\"fuzzy\", \"coverhunter\", \"shs100k2_val\")\n",
    "\n",
    "model_fuzzy_ch = xgb.XGBRanker(**params)\n",
    "model_fuzzy_ch.fit(X_train, y_train, qid=qids_train, eval_set=[(X_val, y_val)], eval_qid=[qids_val])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.8984), tensor(4.4656))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_model = \"fuzzy\"\n",
    "audio_model = \"coverhunter\"\n",
    "dataset = \"shs100k2_test\"\n",
    "out_path = os.path.join(\"preds\", f\"{text_model}_{audio_model}\", dataset)\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "X_test, y_test, qids_test = get_ensemble_data(text_model, audio_model , dataset)\n",
    "mapr, mr1r = compute_metrics(X_test, y_test, qids_test, model_fuzzy_ch, out_path)\n",
    "mapr, mr1r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.8441), tensor(5.5666))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_model = \"fuzzy\"\n",
    "audio_model = \"coverhunter\"\n",
    "dataset = \"da-tacos\"\n",
    "out_path = os.path.join(\"preds\", f\"{text_model}_{audio_model}\", dataset)\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "X_test, y_test, qids_test = get_ensemble_data(text_model, audio_model , dataset)\n",
    "mapr, mr1r = compute_metrics(X_test, y_test, qids_test, model_fuzzy_ch, out_path)\n",
    "mapr, mr1r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.7757), tensor(7.7200))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_model = \"fuzzy\"\n",
    "audio_model = \"coverhunter\"\n",
    "dataset = \"da-tacos_difficult\"\n",
    "out_path = os.path.join(\"preds\", f\"{text_model}_{audio_model}\", dataset)\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "X_test, y_test, qids_test = get_ensemble_data(text_model, audio_model , dataset)\n",
    "mapr, mr1r = compute_metrics(X_test, y_test, qids_test, model_fuzzy_ch, out_path)\n",
    "mapr, mr1r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.8317), tensor(7.0258))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_model = \"fuzzy\"\n",
    "audio_model = \"coverhunter\"\n",
    "dataset = \"shs100k2_test_difficult\"\n",
    "out_path = os.path.join(\"preds\", f\"{text_model}_{audio_model}\", dataset)\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "X_test, y_test, qids_test = get_ensemble_data(text_model, audio_model , dataset)\n",
    "mapr, mr1r = compute_metrics(X_test, y_test, qids_test, model_fuzzy_ch, out_path)\n",
    "mapr, mr1r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.9944), tensor(1.))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_model = \"fuzzy\"\n",
    "audio_model = \"coverhunter\"\n",
    "dataset = \"shs100k2_test_balanced\"\n",
    "out_path = os.path.join(\"preds\", f\"{text_model}_{audio_model}\", dataset)\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "X_test, y_test, qids_test = get_ensemble_data(text_model, audio_model , dataset)\n",
    "mapr, mr1r = compute_metrics(X_test, y_test, qids_test, model_fuzzy_ch, out_path)\n",
    "mapr, mr1r\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.9742), tensor(1.0338))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_model = \"fuzzy\"\n",
    "audio_model = \"coverhunter\"\n",
    "dataset = \"da-tacos_balanced\"\n",
    "out_path = os.path.join(\"preds\", f\"{text_model}_{audio_model}\", dataset)\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "X_test, y_test, qids_test = get_ensemble_data(text_model, audio_model , dataset)\n",
    "mapr, mr1r = compute_metrics(X_test, y_test, qids_test, model_fuzzy_ch, out_path)\n",
    "mapr, mr1r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRanker(base_score=None, booster=None, callbacks=None, colsample_bylevel=None,\n",
       "          colsample_bynode=None, colsample_bytree=None, device=None,\n",
       "          early_stopping_rounds=None, enable_categorical=False,\n",
       "          eval_metric=None, feature_types=None, gamma=None, grow_policy=None,\n",
       "          importance_type=None, interaction_constraints=None,\n",
       "          lambdarank_num_pair_per_sample=6, lambdarank_pair_method=&#x27;topk&#x27;,\n",
       "          learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "          max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "          max_leaves=None, min_child_weight=None, missing=nan,\n",
       "          monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "          n_jobs=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRanker</label><div class=\"sk-toggleable__content\"><pre>XGBRanker(base_score=None, booster=None, callbacks=None, colsample_bylevel=None,\n",
       "          colsample_bynode=None, colsample_bytree=None, device=None,\n",
       "          early_stopping_rounds=None, enable_categorical=False,\n",
       "          eval_metric=None, feature_types=None, gamma=None, grow_policy=None,\n",
       "          importance_type=None, interaction_constraints=None,\n",
       "          lambdarank_num_pair_per_sample=6, lambdarank_pair_method=&#x27;topk&#x27;,\n",
       "          learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "          max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "          max_leaves=None, min_child_weight=None, missing=nan,\n",
       "          monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "          n_jobs=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRanker(base_score=None, booster=None, callbacks=None, colsample_bylevel=None,\n",
       "          colsample_bynode=None, colsample_bytree=None, device=None,\n",
       "          early_stopping_rounds=None, enable_categorical=False,\n",
       "          eval_metric=None, feature_types=None, gamma=None, grow_policy=None,\n",
       "          importance_type=None, interaction_constraints=None,\n",
       "          lambdarank_num_pair_per_sample=6, lambdarank_pair_method='topk',\n",
       "          learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "          max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "          max_leaves=None, min_child_weight=None, missing=nan,\n",
       "          monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "          n_jobs=None, ...)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, qids_train = get_ensemble_data(\"fuzzy\", \"cqtnet\", \"shs100k_1000\")\n",
    "X_val, y_val, qids_val = get_ensemble_data(\"fuzzy\", \"cqtnet\", \"shs100k2_val\")\n",
    "\n",
    "model_fuzzy_cq= xgb.XGBRanker(**params)\n",
    "model_fuzzy_cq.fit(X_train, y_train, qid=qids_train, eval_set=[(X_val, y_val)], eval_qid=[qids_val])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.7510), tensor(14.9221))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_model = \"fuzzy\"\n",
    "audio_model = \"cqtnet\"\n",
    "dataset = \"shs100k2_test\"\n",
    "out_path = os.path.join(\"preds\", f\"{text_model}_{audio_model}\", dataset)\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "X_test, y_test, qids_test = get_ensemble_data(text_model, audio_model , dataset)\n",
    "mapr, mr1r = compute_metrics(X_test, y_test, qids_test, model_fuzzy_cq, out_path)\n",
    "mapr, mr1r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.8040), tensor(4.1573))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_model = \"fuzzy\"\n",
    "audio_model = \"cqtnet\"\n",
    "dataset = \"da-tacos\"\n",
    "out_path = os.path.join(\"preds\", f\"{text_model}_{audio_model}\", dataset)\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "X_test, y_test, qids_test = get_ensemble_data(text_model, audio_model , dataset)\n",
    "mapr, mr1r = compute_metrics(X_test, y_test, qids_test, model_fuzzy_cq, out_path)\n",
    "mapr, mr1r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.8327), tensor(3.8971))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_model = \"fuzzy\"\n",
    "audio_model = \"cqtnet\"\n",
    "dataset = \"da-tacos_difficult\"\n",
    "out_path = os.path.join(\"preds\", f\"{text_model}_{audio_model}\", dataset)\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "X_test, y_test, qids_test = get_ensemble_data(text_model, audio_model , dataset)\n",
    "mapr, mr1r = compute_metrics(X_test, y_test, qids_test, model_fuzzy_cq, out_path)\n",
    "mapr, mr1r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.8556), tensor(2.8387))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_model = \"fuzzy\"\n",
    "audio_model = \"cqtnet\"\n",
    "dataset = \"shs100k2_test_difficult\"\n",
    "out_path = os.path.join(\"preds\", f\"{text_model}_{audio_model}\", dataset)\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "X_test, y_test, qids_test = get_ensemble_data(text_model, audio_model , dataset)\n",
    "mapr, mr1r = compute_metrics(X_test, y_test, qids_test, model_fuzzy_cq, out_path)\n",
    "mapr, mr1r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.9672), tensor(1.0743))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_model = \"fuzzy\"\n",
    "audio_model = \"cqtnet\"\n",
    "dataset = \"shs100k2_test_balanced\"\n",
    "out_path = os.path.join(\"preds\", f\"{text_model}_{audio_model}\", dataset)\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "X_test, y_test, qids_test = get_ensemble_data(text_model, audio_model , dataset)\n",
    "mapr, mr1r = compute_metrics(X_test, y_test, qids_test, model_fuzzy_cq, out_path)\n",
    "mapr, mr1r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.9542), tensor(1.2230))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_model = \"fuzzy\"\n",
    "audio_model = \"cqtnet\"\n",
    "dataset = \"da-tacos_balanced\"\n",
    "out_path = os.path.join(\"preds\", f\"{text_model}_{audio_model}\", dataset)\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "X_test, y_test, qids_test = get_ensemble_data(text_model, audio_model , dataset)\n",
    "mapr, mr1r = compute_metrics(X_test, y_test, qids_test, model_fuzzy_cq, out_path)\n",
    "mapr, mr1r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S-BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRanker(base_score=None, booster=None, callbacks=None, colsample_bylevel=None,\n",
       "          colsample_bynode=None, colsample_bytree=None, device=None,\n",
       "          early_stopping_rounds=None, enable_categorical=False,\n",
       "          eval_metric=None, feature_types=None, gamma=None, grow_policy=None,\n",
       "          importance_type=None, interaction_constraints=None,\n",
       "          lambdarank_num_pair_per_sample=6, lambdarank_pair_method=&#x27;topk&#x27;,\n",
       "          learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "          max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "          max_leaves=None, min_child_weight=None, missing=nan,\n",
       "          monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "          n_jobs=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRanker</label><div class=\"sk-toggleable__content\"><pre>XGBRanker(base_score=None, booster=None, callbacks=None, colsample_bylevel=None,\n",
       "          colsample_bynode=None, colsample_bytree=None, device=None,\n",
       "          early_stopping_rounds=None, enable_categorical=False,\n",
       "          eval_metric=None, feature_types=None, gamma=None, grow_policy=None,\n",
       "          importance_type=None, interaction_constraints=None,\n",
       "          lambdarank_num_pair_per_sample=6, lambdarank_pair_method=&#x27;topk&#x27;,\n",
       "          learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "          max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "          max_leaves=None, min_child_weight=None, missing=nan,\n",
       "          monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "          n_jobs=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRanker(base_score=None, booster=None, callbacks=None, colsample_bylevel=None,\n",
       "          colsample_bynode=None, colsample_bytree=None, device=None,\n",
       "          early_stopping_rounds=None, enable_categorical=False,\n",
       "          eval_metric=None, feature_types=None, gamma=None, grow_policy=None,\n",
       "          importance_type=None, interaction_constraints=None,\n",
       "          lambdarank_num_pair_per_sample=6, lambdarank_pair_method='topk',\n",
       "          learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "          max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "          max_leaves=None, min_child_weight=None, missing=nan,\n",
       "          monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "          n_jobs=None, ...)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, qids_train = get_ensemble_data(\"sentence-transformers\", \"coverhunter\", \"shs100k_1000\")\n",
    "X_val, y_val, qids_val = get_ensemble_data(\"sentence-transformers\", \"coverhunter\", \"shs100k2_val\")\n",
    "\n",
    "model_sbert_ch = xgb.XGBRanker(**params)\n",
    "model_sbert_ch.fit(X_train, y_train, qid=qids_train, eval_set=[(X_val, y_val)], eval_qid=[qids_val])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.9325), tensor(3.5781))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_model = \"sentence-transformers\"\n",
    "audio_model = \"coverhunter\"\n",
    "dataset = \"shs100k2_test\"\n",
    "out_path = os.path.join(\"preds\", f\"{text_model}_{audio_model}\", dataset)\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "X_test, y_test, qids_test = get_ensemble_data(text_model, audio_model , dataset)\n",
    "mapr, mr1r = compute_metrics(X_test, y_test, qids_test, model_sbert_ch, out_path)\n",
    "mapr, mr1r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.9340), tensor(3.0018))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_model = \"sentence-transformers\"\n",
    "audio_model = \"coverhunter\"\n",
    "dataset = \"da-tacos\"\n",
    "out_path = os.path.join(\"preds\", f\"{text_model}_{audio_model}\", dataset)\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "X_test, y_test, qids_test = get_ensemble_data(text_model, audio_model , dataset)\n",
    "mapr, mr1r = compute_metrics(X_test, y_test, qids_test, model_sbert_ch, out_path)\n",
    "mapr, mr1r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.7979), tensor(3.3714))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_model = \"sentence-transformers\"\n",
    "audio_model = \"coverhunter\"\n",
    "dataset = \"da-tacos_difficult\"\n",
    "out_path = os.path.join(\"preds\", f\"{text_model}_{audio_model}\", dataset)\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "X_test, y_test, qids_test = get_ensemble_data(text_model, audio_model , dataset)\n",
    "mapr, mr1r = compute_metrics(X_test, y_test, qids_test, model_sbert_ch, out_path)\n",
    "mapr, mr1r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.8662), tensor(3.0387))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_model = \"sentence-transformers\"\n",
    "audio_model = \"coverhunter\"\n",
    "dataset = \"shs100k2_test_difficult\"\n",
    "out_path = os.path.join(\"preds\", f\"{text_model}_{audio_model}\", dataset)\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "X_test, y_test, qids_test = get_ensemble_data(text_model, audio_model , dataset)\n",
    "mapr, mr1r = compute_metrics(X_test, y_test, qids_test, model_sbert_ch, out_path)\n",
    "mapr, mr1r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRanker(base_score=None, booster=None, callbacks=None, colsample_bylevel=None,\n",
       "          colsample_bynode=None, colsample_bytree=None, device=None,\n",
       "          early_stopping_rounds=None, enable_categorical=False,\n",
       "          eval_metric=None, feature_types=None, gamma=None, grow_policy=None,\n",
       "          importance_type=None, interaction_constraints=None,\n",
       "          lambdarank_num_pair_per_sample=6, lambdarank_pair_method=&#x27;topk&#x27;,\n",
       "          learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "          max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "          max_leaves=None, min_child_weight=None, missing=nan,\n",
       "          monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "          n_jobs=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRanker</label><div class=\"sk-toggleable__content\"><pre>XGBRanker(base_score=None, booster=None, callbacks=None, colsample_bylevel=None,\n",
       "          colsample_bynode=None, colsample_bytree=None, device=None,\n",
       "          early_stopping_rounds=None, enable_categorical=False,\n",
       "          eval_metric=None, feature_types=None, gamma=None, grow_policy=None,\n",
       "          importance_type=None, interaction_constraints=None,\n",
       "          lambdarank_num_pair_per_sample=6, lambdarank_pair_method=&#x27;topk&#x27;,\n",
       "          learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "          max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "          max_leaves=None, min_child_weight=None, missing=nan,\n",
       "          monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "          n_jobs=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRanker(base_score=None, booster=None, callbacks=None, colsample_bylevel=None,\n",
       "          colsample_bynode=None, colsample_bytree=None, device=None,\n",
       "          early_stopping_rounds=None, enable_categorical=False,\n",
       "          eval_metric=None, feature_types=None, gamma=None, grow_policy=None,\n",
       "          importance_type=None, interaction_constraints=None,\n",
       "          lambdarank_num_pair_per_sample=6, lambdarank_pair_method='topk',\n",
       "          learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "          max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "          max_leaves=None, min_child_weight=None, missing=nan,\n",
       "          monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "          n_jobs=None, ...)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, qids_train = get_ensemble_data(\"sentence-transformers\", \"cqtnet\", \"shs100k_1000\")\n",
    "X_val, y_val, qids_val = get_ensemble_data(\"sentence-transformers\", \"cqtnet\", \"shs100k2_val\")\n",
    "\n",
    "model_sbert_cq = xgb.XGBRanker(**params)\n",
    "model_sbert_cq.fit(X_train, y_train, qid=qids_train, eval_set=[(X_val, y_val)], eval_qid=[qids_val])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.8454), tensor(12.1427))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_model = \"sentence-transformers\"\n",
    "audio_model = \"cqtnet\"\n",
    "dataset = \"shs100k2_test\"\n",
    "out_path = os.path.join(\"preds\", f\"{text_model}_{audio_model}\", dataset)\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "X_test, y_test, qids_test = get_ensemble_data(text_model, audio_model , dataset)\n",
    "mapr, mr1r = compute_metrics(X_test, y_test, qids_test, model_sbert_cq, out_path)\n",
    "mapr, mr1r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.9132), tensor(3.0571))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_model = \"sentence-transformers\"\n",
    "audio_model = \"cqtnet\"\n",
    "dataset = \"da-tacos\"\n",
    "out_path = os.path.join(\"preds\", f\"{text_model}_{audio_model}\", dataset)\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "X_test, y_test, qids_test = get_ensemble_data(text_model, audio_model , dataset)\n",
    "mapr, mr1r = compute_metrics(X_test, y_test, qids_test, model_sbert_cq, out_path)\n",
    "mapr, mr1r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.8636), tensor(2.4903))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_model = \"sentence-transformers\"\n",
    "audio_model = \"cqtnet\"\n",
    "dataset = \"shs100k2_test_difficult\"\n",
    "out_path = os.path.join(\"preds\", f\"{text_model}_{audio_model}\", dataset)\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "X_test, y_test, qids_test = get_ensemble_data(text_model, audio_model , dataset)\n",
    "mapr, mr1r = compute_metrics(X_test, y_test, qids_test, model_sbert_cq, out_path)\n",
    "mapr, mr1r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.8592), tensor(2.7943))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_model = \"sentence-transformers\"\n",
    "audio_model = \"cqtnet\"\n",
    "dataset = \"da-tacos_difficult\"\n",
    "out_path = os.path.join(\"preds\", f\"{text_model}_{audio_model}\", dataset)\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "X_test, y_test, qids_test = get_ensemble_data(text_model, audio_model , dataset)\n",
    "mapr, mr1r = compute_metrics(X_test, y_test, qids_test, model_sbert_cq, out_path)\n",
    "mapr, mr1r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ditto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRanker(base_score=None, booster=None, callbacks=None, colsample_bylevel=None,\n",
       "          colsample_bynode=None, colsample_bytree=None, device=None,\n",
       "          early_stopping_rounds=None, enable_categorical=False,\n",
       "          eval_metric=None, feature_types=None, gamma=None, grow_policy=None,\n",
       "          importance_type=None, interaction_constraints=None,\n",
       "          lambdarank_num_pair_per_sample=6, lambdarank_pair_method=&#x27;topk&#x27;,\n",
       "          learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "          max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "          max_leaves=None, min_child_weight=None, missing=nan,\n",
       "          monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "          n_jobs=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRanker</label><div class=\"sk-toggleable__content\"><pre>XGBRanker(base_score=None, booster=None, callbacks=None, colsample_bylevel=None,\n",
       "          colsample_bynode=None, colsample_bytree=None, device=None,\n",
       "          early_stopping_rounds=None, enable_categorical=False,\n",
       "          eval_metric=None, feature_types=None, gamma=None, grow_policy=None,\n",
       "          importance_type=None, interaction_constraints=None,\n",
       "          lambdarank_num_pair_per_sample=6, lambdarank_pair_method=&#x27;topk&#x27;,\n",
       "          learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "          max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "          max_leaves=None, min_child_weight=None, missing=nan,\n",
       "          monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "          n_jobs=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRanker(base_score=None, booster=None, callbacks=None, colsample_bylevel=None,\n",
       "          colsample_bynode=None, colsample_bytree=None, device=None,\n",
       "          early_stopping_rounds=None, enable_categorical=False,\n",
       "          eval_metric=None, feature_types=None, gamma=None, grow_policy=None,\n",
       "          importance_type=None, interaction_constraints=None,\n",
       "          lambdarank_num_pair_per_sample=6, lambdarank_pair_method='topk',\n",
       "          learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "          max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "          max_leaves=None, min_child_weight=None, missing=nan,\n",
       "          monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "          n_jobs=None, ...)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, qids_train = get_ensemble_data(\"ditto\", \"coverhunter\", \"shs100k_1000\")\n",
    "X_val, y_val, qids_val = get_ensemble_data(\"ditto\", \"coverhunter\", \"shs100k2_val_balanced\")\n",
    "\n",
    "model_ditto_ch = xgb.XGBRanker(**params)\n",
    "model_ditto_ch.fit(X_train, y_train, qid=qids_train, eval_set=[(X_val, y_val)], eval_qid=[qids_val])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.8280), tensor(3.6581))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_model = \"ditto\"\n",
    "audio_model = \"coverhunter\"\n",
    "dataset = \"shs100k2_test_difficult\"\n",
    "out_path = os.path.join(\"preds\", f\"{text_model}_{audio_model}\", dataset)\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "X_test, y_test, qids_test = get_ensemble_data(text_model, audio_model , dataset)\n",
    "mapr, mr1r = compute_metrics(X_test, y_test, qids_test, model_ditto_ch, out_path)\n",
    "mapr, mr1r\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.7761), tensor(2.9086))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_model = \"ditto\"\n",
    "audio_model = \"coverhunter\"\n",
    "dataset = \"da-tacos_difficult\"\n",
    "out_path = os.path.join(\"preds\", f\"{text_model}_{audio_model}\", dataset)\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "X_test, y_test, qids_test = get_ensemble_data(text_model, audio_model , dataset)\n",
    "mapr, mr1r = compute_metrics(X_test, y_test, qids_test, model_ditto_ch, out_path)\n",
    "mapr, mr1r\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRanker(base_score=None, booster=None, callbacks=None, colsample_bylevel=None,\n",
       "          colsample_bynode=None, colsample_bytree=None, device=None,\n",
       "          early_stopping_rounds=None, enable_categorical=False,\n",
       "          eval_metric=None, feature_types=None, gamma=None, grow_policy=None,\n",
       "          importance_type=None, interaction_constraints=None,\n",
       "          lambdarank_num_pair_per_sample=6, lambdarank_pair_method=&#x27;topk&#x27;,\n",
       "          learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "          max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "          max_leaves=None, min_child_weight=None, missing=nan,\n",
       "          monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "          n_jobs=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRanker</label><div class=\"sk-toggleable__content\"><pre>XGBRanker(base_score=None, booster=None, callbacks=None, colsample_bylevel=None,\n",
       "          colsample_bynode=None, colsample_bytree=None, device=None,\n",
       "          early_stopping_rounds=None, enable_categorical=False,\n",
       "          eval_metric=None, feature_types=None, gamma=None, grow_policy=None,\n",
       "          importance_type=None, interaction_constraints=None,\n",
       "          lambdarank_num_pair_per_sample=6, lambdarank_pair_method=&#x27;topk&#x27;,\n",
       "          learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "          max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "          max_leaves=None, min_child_weight=None, missing=nan,\n",
       "          monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "          n_jobs=None, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRanker(base_score=None, booster=None, callbacks=None, colsample_bylevel=None,\n",
       "          colsample_bynode=None, colsample_bytree=None, device=None,\n",
       "          early_stopping_rounds=None, enable_categorical=False,\n",
       "          eval_metric=None, feature_types=None, gamma=None, grow_policy=None,\n",
       "          importance_type=None, interaction_constraints=None,\n",
       "          lambdarank_num_pair_per_sample=6, lambdarank_pair_method='topk',\n",
       "          learning_rate=None, max_bin=None, max_cat_threshold=None,\n",
       "          max_cat_to_onehot=None, max_delta_step=None, max_depth=None,\n",
       "          max_leaves=None, min_child_weight=None, missing=nan,\n",
       "          monotone_constraints=None, multi_strategy=None, n_estimators=None,\n",
       "          n_jobs=None, ...)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, qids_train = get_ensemble_data(\"ditto\", \"cqtnet\", \"shs100k_1000\")\n",
    "X_val, y_val, qids_val = get_ensemble_data(\"ditto\", \"cqtnet\", \"shs100k2_val_balanced\")\n",
    "\n",
    "model_ditto_cq = xgb.XGBRanker(**params)\n",
    "model_ditto_cq.fit(X_train, y_train, qid=qids_train, eval_set=[(X_val, y_val)], eval_qid=[qids_val])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.8490), tensor(2.0114))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_model = \"ditto\"\n",
    "audio_model = \"cqtnet\"\n",
    "dataset = \"da-tacos_difficult\"\n",
    "out_path = os.path.join(\"preds\", f\"{text_model}_{audio_model}\", dataset)\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "X_test, y_test, qids_test = get_ensemble_data(text_model, audio_model , dataset)\n",
    "mapr, mr1r = compute_metrics(X_test, y_test, qids_test, model_ditto_cq, out_path)\n",
    "mapr, mr1r\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.8650), tensor(2.5161))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_model = \"ditto\"\n",
    "audio_model = \"cqtnet\"\n",
    "dataset = \"shs100k2_test_difficult\"\n",
    "out_path = os.path.join(\"preds\", f\"{text_model}_{audio_model}\", dataset)\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "X_test, y_test, qids_test = get_ensemble_data(text_model, audio_model , dataset)\n",
    "mapr, mr1r = compute_metrics(X_test, y_test, qids_test, model_ditto_cq, out_path)\n",
    "mapr, mr1r\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6492) tensor(14.5633)\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"da-tacos_unique\"\n",
    "tokenizer=\"bert-base-multilingual-cased\"\n",
    "\n",
    "csi_path = \"/data/csi_datasets/\"\n",
    "metadata_path = \"/data/yt_metadata.parquet\"\n",
    "dataset = TestDataset(\n",
    "    dataset_name,\n",
    "    csi_path,\n",
    "    metadata_path,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "preds = torch.load(f\"preds/ditto/{tokenizer}/{dataset_name}/preds.pt\")\n",
    "target = dataset.get_target_matrix()\n",
    "\n",
    "# get indexes\n",
    "m, n = target.shape\n",
    "indexes = torch.arange(m).view(-1, 1).expand(-1, n).cpu()\n",
    "\n",
    "map=mean_average_precision(preds.cpu(), target.cpu(), indexes.cpu())\n",
    "mr1=mean_rank_1(preds.cpu(), target.cpu())\n",
    "\n",
    "print(map, mr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample_data(df, k, N):\n",
    "    \"\"\"\n",
    "    Downsample the DataFrame to include k items per class, dropping classes if necessary.\n",
    "\n",
    "    Parameters:\n",
    "    - df: DataFrame to be downsampled.\n",
    "    - k: Number of items per class.\n",
    "    - N: Size of the downsampled dataset.\n",
    "\n",
    "    Returns:\n",
    "    - downsampled_df: Downsampled DataFrame.\n",
    "    \"\"\"\n",
    "    # Ensure k is less than or equal to N\n",
    "    if k > N:\n",
    "        raise ValueError(\"k must be less than or equal to N.\")\n",
    "\n",
    "    # Group by 'set_id' and check the size of each group\n",
    "    group_sizes = df.groupby('set_id').size().reset_index(name='size')\n",
    "\n",
    "    # Filter groups with size less than k\n",
    "    valid_groups = group_sizes[group_sizes['size'] >= k]['set_id']\n",
    "\n",
    "    # Filter the original DataFrame to include only valid groups\n",
    "    df_valid = df[df['set_id'].isin(valid_groups)]\n",
    "\n",
    "    # Define a function to downsample each group\n",
    "    def downsample_group(group):\n",
    "        return group.sample(min(k, len(group)))\n",
    "\n",
    "    # Apply the downsampling operation to each group based on 'set_id'\n",
    "    downsampled_df = df_valid.groupby('set_id', group_keys=False).apply(downsample_group)\n",
    "\n",
    "    return downsampled_df\n",
    "\n",
    "    \n",
    "val_downsampled = downsample_data(val_data, 5, 150)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch21",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
